{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IhYukKmCUmc",
    "outputId": "74ea3bf6-dcdc-474f-ccb3-28b8d70f56c0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2LkC-0L7CVM_"
   },
   "outputs": [],
   "source": [
    "# !cp drive/\"MyDrive\"/train.pkl train.pkl\n",
    "# !cp drive/\"MyDrive\"/test_no_target.pkl test_no_target.pkl  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iJH167C75too"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2137)\n",
    "torch.manual_seed(2137)\n",
    "random.seed(2137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHzXs6WANS5R",
    "outputId": "e4a807d9-a355-463f-d9aa-72402eba1dfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1630.,  478.,  154.,  441.,  236.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw  = pd.read_pickle(\"./train.pkl\")\n",
    "classes_count = torch.zeros(5)\n",
    "for x in range(len(train_raw)):\n",
    "    classes_count[train_raw[x][1]] += 1;\n",
    "classes_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsequencing\n",
    "sequence_limit = 400\n",
    "train_cropped = []\n",
    "for x in range(len(train_raw)):\n",
    "#     parts = int(len(train_raw[x][0])/sequence_limit)+1\n",
    "#     for i in range(parts):\n",
    "#         train_cropped.append((train_raw[x][0][i*sequence_limit:min((i+1)*sequence_limit, len(train_raw[x][0]))], train_raw[x][1]))\n",
    "    train_cropped.append((train_raw[x][0][:min(sequence_limit, len(train_raw[x][0]))], train_raw[x][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  3.4100, 10.5844,  3.6961,  6.9068])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw  =train_cropped\n",
    "classes_count = torch.zeros(5)\n",
    "for x in range(len(train_raw)):\n",
    "      classes_count[train_raw[x][1]] += 1\n",
    "classes_weight = torch.ones(5)*torch.max(classes_count)/classes_count\n",
    "classes_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omB_BvnLDs8c",
    "outputId": "91b696e9-5b1d-4734-9832-8764544c0e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2939.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downsampling\n",
    "class_limit = 600\n",
    "classes_count = torch.zeros(5)\n",
    "train_seq = []\n",
    "train_label = []\n",
    "for x in range(len(train_raw)):\n",
    "#   if classes_count[train_raw[x][1]] < class_limit:\n",
    "    if True:\n",
    "        classes_count[train_raw[x][1]] += 1\n",
    "        train_seq.append(torch.from_numpy(train_raw[x][0]))\n",
    "        train_label.append(train_raw[x][1])\n",
    "torch.sum(classes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkjFWXDKEbjU",
    "outputId": "f4ef7635-8794-4b2c-d991-2a936b780c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 2939])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#padding\n",
    "train_seq = pad_sequence(train_seq, batch_first=False, padding_value=0)\n",
    "train_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfRYdHZAEoMP",
    "outputId": "5b3192d8-2b70-48ae-a078-4a1f83c27cb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x20b084f7278>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.transpose(train_seq.float(),0, 1)\n",
    "data_targets = torch.Tensor(train_label).long()\n",
    "train_indices = np.random.rand(len(data))>0.3\n",
    "test_indices = ~train_indices\n",
    "train_set = torch.utils.data.TensorDataset(data[train_indices], data_targets[train_indices])\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
    "test_data, test_targets = data[test_indices], data_targets[test_indices]\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GDc-MSUVNxGY"
   },
   "outputs": [],
   "source": [
    "class MusicianFinder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size= hidden_size, num_layers = num_layers)\n",
    "        self.inc0 = nn.Conv1d(1, 1, (1, 11), stride=3)\n",
    "        self.inc1 = nn.Conv1d(1, 1, (1, 33), stride=7)\n",
    "        self.inc2 = nn.Conv1d(1, 1, (1, 55), stride=15)\n",
    "        self.inc3 = nn.Conv1d(1, 1, (1, 77), stride=35)\n",
    "        self.mpinc0 = nn.MaxPool1d(5)\n",
    "        self.mpinc1 = nn.MaxPool1d(5)\n",
    "        self.mpinc2 = nn.MaxPool1d(5)\n",
    "        self.mpinc3 = nn.MaxPool1d(5)\n",
    "        self.lin0 = nn.Linear(sequence_limit, 50)\n",
    "        self.d0 = nn.Dropout(0.6)\n",
    "        self.act0 =  nn.Sigmoid()\n",
    "        self.lin1 = nn.Linear(hidden_size*sequence_limit, 150)\n",
    "        self.d1 = nn.Dropout(0.6)\n",
    "        self.act1 =  nn.ReLU()\n",
    "        self.lin2 = nn.Linear(hidden_size*sequence_limit+7606, 500)\n",
    "        self.d2 = nn.Dropout(0.6)\n",
    "        self.act2 =  nn.Sigmoid()\n",
    "        self.lin3 = nn.Linear(500, out_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "#         emb = self.lin0(torch.squeeze(x, 2))\n",
    "#         emb = self.d0(emb)\n",
    "#         emb = self.act0(emb) \n",
    "        \n",
    "        x = torch.transpose(x,0,1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        all_outputs = torch.transpose(all_outputs,0,1)\n",
    "        out = torch.flatten(all_outputs, 1)\n",
    "        \n",
    "        inc = out.unsqueeze(1).unsqueeze(2)\n",
    "        linc0 = self.inc1(inc)\n",
    "        linc1 = self.inc1(inc)\n",
    "        linc2 = self.inc2(inc)\n",
    "        linc3 = self.inc3(inc)\n",
    "        linc0, linc1, linc2, linc3 = linc0.squeeze(2), linc1.squeeze(2), linc2.squeeze(2), linc3.squeeze(2)\n",
    "#         linc0 = self.mpinc0(linc0)\n",
    "#         linc1 = self.mpinc1(linc1)\n",
    "#         linc2 = self.mpinc2(linc2)\n",
    "#         linc3 = self.mpinc3(linc3)\n",
    "        linc0, linc1, linc2, linc3 = linc0.squeeze(1), linc1.squeeze(1), linc2.squeeze(1), linc3.squeeze(1)\n",
    "        inc = torch.cat((linc0,linc1,linc2,linc3),1)\n",
    "        \n",
    "#         x = self.lin1(out)\n",
    "#         x = self.d1(x)\n",
    "#         x = self.act1(x)\n",
    "        x = torch.cat((out, inc),1)\n",
    "        x = self.lin2(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        return x, hidden\n",
    "\n",
    "model = MusicianFinder(1,50,2,5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "rTGXhVwcSkeX",
    "outputId": "98c0b05e-71dc-401d-e05d-e3d3aa7708a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 4.12e+02\n",
      "Accuracy: 0.2929061784897025\n",
      "Epoch: 2, loss: 3.85e+02\n",
      "Epoch: 4, loss: 3.45e+02\n",
      "Epoch: 6, loss: 3.31e+02\n",
      "Epoch: 8, loss: 3.08e+02\n",
      "Epoch: 10, loss: 2.88e+02\n",
      "Accuracy: 0.5835240274599542\n",
      "Epoch: 12, loss: 2.62e+02\n",
      "Epoch: 14, loss: 2.19e+02\n",
      "Epoch: 16, loss: 1.74e+02\n",
      "Epoch: 18, loss: 1.36e+02\n",
      "Epoch: 20, loss: 1.05e+02\n",
      "Accuracy: 0.6567505720823799\n",
      "Epoch: 22, loss: 77.1\n",
      "Epoch: 24, loss: 54.7\n",
      "Epoch: 26, loss: 42.9\n",
      "Epoch: 28, loss: 31.6\n",
      "Epoch: 30, loss: 26.8\n",
      "Accuracy: 0.6739130434782609\n",
      "Epoch: 32, loss: 27.2\n",
      "Epoch: 34, loss: 30.6\n",
      "Epoch: 36, loss: 19.0\n",
      "Epoch: 38, loss: 17.2\n",
      "Epoch: 40, loss: 12.0\n",
      "Accuracy: 0.6853546910755148\n",
      "Epoch: 42, loss: 39.2\n",
      "Epoch: 44, loss: 19.4\n",
      "Epoch: 46, loss: 9.23\n",
      "Epoch: 48, loss: 4.63\n",
      "Epoch: 50, loss: 6.89\n",
      "Accuracy: 0.6498855835240275\n",
      "Epoch: 52, loss: 51.9\n",
      "Epoch: 54, loss: 33.4\n",
      "Epoch: 56, loss: 10.8\n",
      "Epoch: 58, loss: 4.27\n",
      "Epoch: 60, loss: 2.76\n",
      "Accuracy: 0.6750572082379863\n",
      "Epoch: 62, loss: 1.89\n",
      "Epoch: 64, loss: 17.1\n",
      "Epoch: 66, loss: 42.7\n",
      "Epoch: 68, loss: 12.2\n",
      "Epoch: 70, loss: 4.49\n",
      "Accuracy: 0.6784897025171625\n",
      "Epoch: 72, loss: 2.71\n",
      "Epoch: 74, loss: 1.75\n",
      "Epoch: 76, loss: 3.02\n",
      "Epoch: 78, loss: 83.7\n",
      "Epoch: 80, loss: 18.5\n",
      "Accuracy: 0.6384439359267735\n",
      "Epoch: 82, loss: 8.36\n",
      "Epoch: 84, loss: 3.05\n",
      "Epoch: 86, loss: 1.77\n",
      "Epoch: 88, loss: 1.79\n",
      "Epoch: 90, loss: 22.4\n",
      "Accuracy: 0.6018306636155606\n",
      "Epoch: 92, loss: 33.7\n",
      "Epoch: 94, loss: 7.42\n",
      "Epoch: 96, loss: 3.04\n",
      "Epoch: 98, loss: 1.38\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 0.0001)\n",
    "loss_fun = nn.CrossEntropyLoss(weight = classes_weight.to(device) )\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for x, targets in train_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device)\n",
    "        preds, _ = model(x, (hidden, state))\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(preds, targets)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {epoch_loss:.3}\")\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            hidden, state = model.init_hidden(len(test_data))\n",
    "            hidden, state = hidden.to(device), state.to(device)\n",
    "            preds, _ = model(test_data.to(device).unsqueeze(2), (hidden, state))\n",
    "        print(f\"Accuracy: {(torch.argmax(preds,1).cpu() == test_targets).sum().item()/len(test_targets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([481., 153.,  38., 136.,  66.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_count = torch.zeros(5)\n",
    "for x in range(len(test_targets)):\n",
    "      classes_count[test_targets[x]] += 1;\n",
    "classes_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e-oG9LKPaLIW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6739130434782609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 3, 3, 1, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 3, 3, 4, 0, 0, 0, 0, 3, 3, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "        3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2,\n",
       "        0, 0, 3, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 3, 0, 0, 0,\n",
       "        0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0,\n",
       "        0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 2, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 4, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        3, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0,\n",
       "        0, 3, 0, 3, 2, 2, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 3, 0, 4, 4, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        3, 3, 4, 1, 1, 1, 4, 1, 4, 4, 1, 1, 2, 1, 2, 3, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        1, 0, 1, 4, 1, 0, 3, 0, 0, 0, 1, 0, 1, 3, 3, 1, 2, 4, 3, 1, 0, 3, 0, 0,\n",
       "        0, 0, 1, 1, 0, 3, 0, 4, 1, 0, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 4, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 3, 2, 1, 1, 0, 0, 3, 0, 0, 2, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        3, 0, 0, 0, 2, 1, 2, 0, 0, 2, 0, 3, 1, 3, 4, 0, 1, 1, 0, 0, 0, 1, 2, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 2, 1, 3, 1, 1, 3, 3, 0, 1, 3, 3, 3, 1, 2, 2, 3, 3,\n",
       "        0, 1, 0, 2, 4, 2, 2, 3, 3, 2, 2, 3, 0, 2, 3, 3, 3, 2, 3, 0, 0, 3, 0, 3,\n",
       "        1, 0, 1, 0, 0, 3, 3, 3, 0, 3, 3, 2, 3, 3, 0, 3, 3, 3, 3, 3, 0, 1, 3, 3,\n",
       "        0, 0, 3, 1, 4, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0,\n",
       "        3, 3, 0, 3, 0, 1, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 4,\n",
       "        3, 3, 3, 3, 4, 3, 3, 3, 0, 2, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 2, 1, 0, 0,\n",
       "        3, 2, 3, 3, 1, 3, 3, 3, 0, 3, 3, 3, 3, 3, 2, 3, 3, 3, 0, 3, 0, 4, 3, 0,\n",
       "        3, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 1, 3, 0, 3, 4, 4, 0, 4, 4, 3, 4, 1,\n",
       "        4, 1, 4, 2, 4, 4, 1, 3, 4, 4, 4, 4, 0, 0, 0, 1, 4, 3, 3, 1, 3, 4, 0, 2,\n",
       "        3, 0, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 3, 0, 3, 3, 4, 0,\n",
       "        4, 4, 4, 3, 3, 4, 4, 4, 4, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hidden, state = model.init_hidden(len(test_data))\n",
    "    hidden, state = hidden.to(device), state.to(device)\n",
    "    preds, _ = model(test_data.to(device).unsqueeze(2), (hidden, state))\n",
    "print(f\"Accuracy: {(torch.argmax(preds,1).cpu() == test_targets).sum().item()/len(test_targets)}\")\n",
    "# for x in range(len(preds)):\n",
    "#     print(f\"{torch.argmax(preds[x])} =? {test_targets[x]}\")\n",
    "torch.argmax(preds,1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tens(t):\n",
    "    f = open(\"BartoszRomanowska.csv\", \"w\")\n",
    "    for i in t:\n",
    "        f.write(f\"{i}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw  = pd.read_pickle(\"./test_no_target.pkl\")\n",
    "len(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = []\n",
    "for x in range(len(test_raw)):\n",
    "    test_seq.append(torch.from_numpy(test_raw[x][:min(sequence_limit, len(test_raw[x]))]))\n",
    "test_seq = pad_sequence(test_seq, batch_first=False, padding_value=0)\n",
    "test_seq = torch.transpose(test_seq.float(),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 926.00 MiB (GPU 0; 2.00 GiB total capacity; 400.76 MiB already allocated; 0 bytes free; 986.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-51e144c82627>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0msave_tens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envtorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-0504003a5d16>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mall_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mall_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envtorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envtorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 582\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    583\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 926.00 MiB (GPU 0; 2.00 GiB total capacity; 400.76 MiB already allocated; 0 bytes free; 986.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hidden, state = model.init_hidden(len(test_seq))\n",
    "    hidden, state = hidden.to(device), state.to(device)\n",
    "    preds, _ = model(test_seq.to(device).unsqueeze(2), (hidden, state))\n",
    "    save_tens(torch.argmax(preds,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = torch.Tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "# for i in range(10):\n",
    "hmm = torch.stack((hmm,hmm+1),0)\n",
    "for i in range(3):\n",
    "    hmm = torch.cat((hmm,4*hmm),0)\n",
    "hmm = hmm.unsqueeze(1).unsqueeze(2)\n",
    "print(hmm.size())\n",
    "m = nn.Conv1d(1, 1, (1,3), stride=1)\n",
    "hmm = m(hmm)\n",
    "print(hmm.size())\n",
    "hmm = hmm.squeeze(2)\n",
    "m = nn.MaxPool1d(3, stride=2)\n",
    "hmm = m(hmm)\n",
    "hmm = hmm.squeeze(1)\n",
    "hmm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> m = nn.Conv1d(16, 33, 3, stride=1)\n",
    ">>> input = torch.randn(20, 16, 50)\n",
    ">>> output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
