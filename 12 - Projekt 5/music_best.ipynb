{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_best.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IhYukKmCUmc",
        "outputId": "f71292cf-208d-42c2-ca98-5383a9765580"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/ssne/train.pkl train.pkl\n",
        "!cp drive/MyDrive/ssne/test_no_target.pkl test_no_target.pkl"
      ],
      "metadata": {
        "id": "2LkC-0L7CVM_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iJH167C75too"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sklearn\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3dOBDAIiHk0",
        "outputId": "4c0ecc65-26ae-40b8-f5ef-f34d3b91867e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 742842589\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "KUDzlTUYqo6A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw = pd.read_pickle(\"./train.pkl\")\n",
        "random.shuffle(train_raw)"
      ],
      "metadata": {
        "id": "KHzXs6WANS5R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: {0: 1630, 2: 154, 3: 441, 4: 236, 1: 478}\n",
            "Min class: 154\n"
          ]
        }
      ],
      "source": [
        "def count_classes(train_set):\n",
        "  classes_count = {}\n",
        "  for x in train_set:\n",
        "    classes_count[x[1]] = classes_count.get(x[1], 0) + 1\n",
        "  return classes_count\n",
        "\n",
        "print(f\"Classes: {count_classes(train_raw)}\")\n",
        "min_class_count = min(count_classes(train_raw).values())\n",
        "print(f\"Min class: {min_class_count}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9iypHPuACfr",
        "outputId": "dc04ff8b-da89-43db-973d-bb4cf538be01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Balancing\n",
        "CLASS_COUNT_LIMIT = 5*min_class_count\n",
        "\n",
        "train_balanced = []\n",
        "classes_counter = {}\n",
        "for x in train_raw:\n",
        "  classes_counter[x[1]] = classes_counter.get(x[1], 0) + 1\n",
        "  if classes_counter[x[1]] <= CLASS_COUNT_LIMIT:\n",
        "    train_balanced.append(x)\n",
        "\n",
        "train_raw = train_balanced\n",
        "print(f\"Classes: {count_classes(train_raw)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSUov6Wwf6ol",
        "outputId": "20aa7b74-095b-4428-d860-330e9edc0979"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: {0: 770, 2: 154, 3: 441, 4: 236, 1: 478}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = []\n",
        "for x in train_raw:\n",
        "  sizes.append(x[0].shape[0])\n",
        "print(f\"Sequence size [min/avr/max]: {min(sizes)}/{sum(sizes)/len(sizes)}/{max(sizes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BGmH0F5ixSC",
        "outputId": "a38de80e-ab00-4358-bd78-e58c57a0460e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence size [min/avr/max]: 4/473.93265993265993/6308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -1.,  -1.,   0.,   0.,   0.,  12.,  12.,  88.,  92.,  92.,  28., 159.,\n",
              "         12.,   0.,   0., 144., 144., 144.,  50.,  50.,  50., 116., 116., 116.,\n",
              "        122., 122., 122., 127.,  88.,  88., 125.,  78., 119., 159., 125.,  47.,\n",
              "         78.,  64., 159.,  92.,  88.,  47.,  12.,   0.,  12.,  12.,  15.,  45.,\n",
              "        124., 112.,  12.,  13., 141.,  12.,  88.,  13.,  92.,  92.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Croping\n",
        "MAX_SEQUENCE_LEN = 40000\n",
        "\n",
        "music_data = []\n",
        "label_data = []\n",
        "for x in train_raw:\n",
        "  music_tensor = torch.tensor(x[0], dtype=torch.float)\n",
        "  music_tensor = music_tensor[:MAX_SEQUENCE_LEN]\n",
        "  music_data.append(music_tensor)\n",
        "  label_data.append(x[1])\n",
        "music_data[0]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSrNWssvACfr",
        "outputId": "873d7602-f828-4f32-d5d4-b2472c83ac60"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size after paddding: 6308\n"
          ]
        }
      ],
      "source": [
        "music_data_padded = pad_sequence(music_data, batch_first=True, padding_value=0)\n",
        "assert len(music_data_padded) == len(label_data)\n",
        "print(f\"Size after paddding: {music_data_padded[0].shape[0]}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yySQ4RdlACfs",
        "outputId": "8d00b533-04c7-4a0e-c1cf-04057d458868"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_TEST_RATIO = 0.9\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_indices = int(TRAIN_TEST_RATIO*len(music_data_padded))\n",
        "\n",
        "train_set = torch.utils.data.TensorDataset(music_data_padded[:train_indices], torch.tensor(label_data[:train_indices]))\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data, test_targets = music_data_padded[train_indices:], label_data[train_indices:]"
      ],
      "metadata": {
        "id": "WfRYdHZAEoMP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
        "    self.fc = nn.Linear(hidden_size*len(music_data_padded[0]), out_size)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "    state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "    return hidden, state\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = torch.transpose(x, 0, 1)\n",
        "    all_outputs, hidden = self.lstm(x, hidden)\n",
        "    all_outputs = torch.transpose(all_outputs,0,1)\n",
        "    out = torch.flatten(all_outputs, 1)\n",
        "    x = self.fc(out)\n",
        "  \n",
        "    return x, hidden"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ixq24WW8ACft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(label_data),y=label_data)\n",
        "class_weights = torch.tensor(class_weights).float()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3GP-7fHNACfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": [
        "def count_accuracy():\n",
        "  with torch.no_grad():\n",
        "    hidden, state = model.init_hidden(len(test_data))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "    preds, _ = model(test_data.to(device).unsqueeze(2),(hidden, state))\n",
        "    p = torch.argmax(preds,1).cpu()\n",
        "    counter = 0\n",
        "    for i in range(len(test_targets)):\n",
        "      if p[i] == test_targets[i]:\n",
        "        counter += 1\n",
        "    return counter/len(test_targets)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aNrDdbQvACfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMRegressor(1, 50, 3, 5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_fun = nn.CrossEntropyLoss(weight = class_weights.to(device))"
      ],
      "metadata": {
        "id": "pzVJESXPE1zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 1.02, acc: 0.567, max_acc: 0.567\n",
            "Epoch: 1, loss: 0.828, acc: 0.639, max_acc: 0.639\n",
            "Epoch: 2, loss: 0.898, acc: 0.654, max_acc: 0.654\n",
            "Epoch: 3, loss: 0.69, acc: 0.663, max_acc: 0.663\n",
            "Epoch: 4, loss: 0.667, acc: 0.688, max_acc: 0.688\n",
            "Epoch: 5, loss: 0.621, acc: 0.688, max_acc: 0.688\n",
            "Epoch: 6, loss: 0.536, acc: 0.606, max_acc: 0.688\n",
            "Epoch: 7, loss: 0.429, acc: 0.596, max_acc: 0.688\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-dd375abf07eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "max_acc = 0\n",
        "for epoch in range(6):\n",
        "  for x, targets in train_loader:\n",
        "    x = x.to(device).unsqueeze(2)\n",
        "    targets = targets.to(device)\n",
        "    hidden, state = model.init_hidden(x.size(0))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "    preds, _ = model(x, (hidden,state))\n",
        "    preds = preds.squeeze(1)\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fun(preds, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  acc = count_accuracy()\n",
        "  max_acc = max(max_acc, acc)\n",
        "  if max_acc - acc > 0.05:\n",
        "    break\n",
        "  print(f\"Epoch: {epoch}, loss: {loss.item():.3}, acc: {acc:.3}, max_acc: {max_acc:.3}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YTmM87qGACfv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "553e734c-4f2a-404b-b88e-e804e3dc0394"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def save_results(tensor):\n",
        "  predictions = tensor.cpu().detach().numpy()\n",
        "  pd.DataFrame(predictions).to_csv(\"result.csv\",header=False, index=False)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RCx8YjssACfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_raw = pd.read_pickle(\"./test_no_target.pkl\")"
      ],
      "metadata": {
        "id": "Vl5sysX2EIxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}