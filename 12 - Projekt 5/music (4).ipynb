{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "music.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IhYukKmCUmc",
    "outputId": "68725e8a-4300-4c37-e896-6058392b6aea"
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#!cp drive/MyDrive/ssne/train.pkl train.pkl\n",
    "#!cp drive/MyDrive/ssne/test_no_target.pkl test_no_target.pkl"
   ],
   "metadata": {
    "id": "2LkC-0L7CVM_"
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "iJH167C75too"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sklearn\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3dOBDAIiHk0",
    "outputId": "6d8713f0-e6ac-4d80-d345-f35799a368a9"
   },
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "seed = 742842589\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ],
   "metadata": {
    "id": "KUDzlTUYqo6A"
   },
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_raw = pd.read_pickle(\"./train.pkl\")\n",
    "random.shuffle(train_raw)"
   ],
   "metadata": {
    "id": "KHzXs6WANS5R"
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {0: 1630, 2: 154, 3: 441, 4: 236, 1: 478}\n",
      "Min class: 154\n"
     ]
    }
   ],
   "source": [
    "def count_classes(train_set):\n",
    "  classes_count = {}\n",
    "  for x in train_set:\n",
    "    classes_count[x[1]] = classes_count.get(x[1], 0) + 1\n",
    "  return classes_count\n",
    "\n",
    "print(f\"Classes: {count_classes(train_raw)}\")\n",
    "min_class_count = min(count_classes(train_raw).values())\n",
    "print(f\"Min class: {min_class_count}\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9iypHPuACfr",
    "outputId": "89c68b3c-0d5a-4430-d309-c0f58dcdac89"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Balancing\n",
    "CLASS_COUNT_LIMIT = 5*min_class_count\n",
    "\n",
    "train_balanced = []\n",
    "classes_counter = {}\n",
    "for x in train_raw:\n",
    "  classes_counter[x[1]] = classes_counter.get(x[1], 0) + 1\n",
    "  if classes_counter[x[1]] <= CLASS_COUNT_LIMIT:\n",
    "    train_balanced.append(x)\n",
    "\n",
    "train_raw = train_balanced\n",
    "print(f\"Classes: {count_classes(train_raw)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSUov6Wwf6ol",
    "outputId": "6db26bcb-e84f-4320-cedb-42b7ebc5ac09"
   },
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {0: 770, 2: 154, 3: 441, 4: 236, 1: 478}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sizes = []\n",
    "for x in train_raw:\n",
    "  sizes.append(x[0].shape[0])\n",
    "print(f\"Sequence size [min/avr/max]: {min(sizes)}/{sum(sizes)/len(sizes)}/{max(sizes)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BGmH0F5ixSC",
    "outputId": "addf01f2-3d03-4196-83aa-ba0fe6406e8c"
   },
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence size [min/avr/max]: 4/473.93265993265993/6308\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ -1.,  -1.,   0.,   0.,   0.,  12.,  12.,  88.,  92.,  92.,  28., 159.,\n         12.,   0.,   0., 144., 144., 144.,  50.,  50.,  50., 116., 116., 116.,\n        122., 122., 122., 127.,  88.,  88., 125.,  78., 119., 159., 125.,  47.,\n         78.,  64., 159.,  92.,  88.,  47.,  12.,   0.,  12.,  12.,  15.,  45.,\n        124., 112.,  12.,  13., 141.,  12.,  88.,  13.,  92.,  92.,   0.,   0.])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Croping\n",
    "MAX_SEQUENCE_LEN = 40000\n",
    "\n",
    "music_data = []\n",
    "label_data = []\n",
    "for x in train_raw:\n",
    "  music_tensor = torch.tensor(x[0], dtype=torch.float)\n",
    "  music_tensor = music_tensor[:MAX_SEQUENCE_LEN]\n",
    "  music_data.append(music_tensor)\n",
    "  label_data.append(x[1])\n",
    "music_data[0]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSrNWssvACfr",
    "outputId": "6a9ab399-c2de-4bae-8c34-c1b9ee29bc6c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after paddding: 6308\n"
     ]
    }
   ],
   "source": [
    "music_data_padded = pad_sequence(music_data, batch_first=True, padding_value=0)\n",
    "assert len(music_data_padded) == len(label_data)\n",
    "print(f\"Size after paddding: {music_data_padded[0].shape[0]}\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yySQ4RdlACfs",
    "outputId": "ea8e8126-cc89-451b-f3ab-ad81a6a41eb6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "TRAIN_TEST_RATIO = 0.9\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_indices = int(TRAIN_TEST_RATIO*len(music_data_padded))\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(music_data_padded[:train_indices], torch.tensor(label_data[:train_indices]))\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_data, test_targets = music_data_padded[train_indices:], label_data[train_indices:]"
   ],
   "metadata": {
    "id": "WfRYdHZAEoMP"
   },
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "class LSTMRegressor(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "    super().__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
    "    self.fc = nn.Linear(hidden_size*len(music_data_padded[0]), out_size)\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "    state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "    return hidden, state\n",
    "\n",
    "  def forward(self, x, hidden):\n",
    "    x = torch.transpose(x, 0, 1)\n",
    "    all_outputs, hidden = self.lstm(x, hidden)\n",
    "    all_outputs = torch.transpose(all_outputs,0,1)\n",
    "    out = torch.flatten(all_outputs, 1)\n",
    "    x = self.fc(out)\n",
    "  \n",
    "    return x, hidden"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ixq24WW8ACft"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(label_data),y=label_data)\n",
    "class_weights = torch.tensor(class_weights).float()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3GP-7fHNACfu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def count_accuracy():\n",
    "  with torch.no_grad():\n",
    "    hidden, state = model.init_hidden(len(test_data))\n",
    "    hidden, state = hidden.to(device), state.to(device)\n",
    "    preds, _ = model(test_data.to(device).unsqueeze(2),(hidden, state))\n",
    "    p = torch.argmax(preds,1).cpu()\n",
    "    counter = 0\n",
    "    for i in range(len(test_targets)):\n",
    "      if p[i] == test_targets[i]:\n",
    "        counter += 1\n",
    "    return counter/len(test_targets)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "aNrDdbQvACfv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = LSTMRegressor(1, 30, 3, 5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fun = nn.CrossEntropyLoss(weight = class_weights.to(device))"
   ],
   "metadata": {
    "id": "pzVJESXPE1zy",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "outputId": "32022ff2-6fff-467d-9e6a-3b999bb1d20e"
   },
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.49 GiB (GPU 0; 4.00 GiB total capacity; 351.06 MiB already allocated; 1.33 GiB free; 760.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20208/1206899668.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m   \u001B[0macc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcount_accuracy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m   \u001B[0mmax_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_acc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0macc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mmax_acc\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0macc\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0.04\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20208/1715512298.py\u001B[0m in \u001B[0;36mcount_accuracy\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mhidden\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit_hidden\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mhidden\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mpreds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhidden\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m     \u001B[0mp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mcounter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kubar\\documents\\studia\\ssne\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20208/1288862375.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, hidden)\u001B[0m\n\u001B[0;32m     14\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m     \u001B[0mall_outputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m     \u001B[0mall_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_outputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kubar\\documents\\studia\\ssne\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kubar\\documents\\studia\\ssne\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    689\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_forward_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_sizes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    690\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mbatch_sizes\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 691\u001B[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001B[0m\u001B[0;32m    692\u001B[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001B[0;32m    693\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 2.49 GiB (GPU 0; 4.00 GiB total capacity; 351.06 MiB already allocated; 1.33 GiB free; 760.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "max_acc = 0\n",
    "for epoch in range(21):\n",
    "  for x, targets in train_loader:\n",
    "    x = x.to(device).unsqueeze(2)\n",
    "    targets = targets.to(device)\n",
    "    hidden, state = model.init_hidden(x.size(0))\n",
    "    hidden, state = hidden.to(device), state.to(device)\n",
    "    preds, _ = model(x, (hidden,state))\n",
    "    preds = preds.squeeze(1)\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fun(preds, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  acc = count_accuracy()\n",
    "  max_acc = max(max_acc, acc)\n",
    "  if max_acc - acc > 0.04:\n",
    "    break\n",
    "  print(f\"Epoch: {epoch}, loss: {loss.item():.3}, acc: {acc:.3}, max_acc: {max_acc:.3}\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YTmM87qGACfv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_results(tensor):\n",
    "  predictions = tensor.cpu().detach().numpy()\n",
    "  pd.DataFrame(predictions).to_csv(\"result.csv\",header=False, index=False)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RCx8YjssACfw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_raw = pd.read_pickle(\"./test_no_target.pkl\")"
   ],
   "metadata": {
    "id": "Vl5sysX2EIxD"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}