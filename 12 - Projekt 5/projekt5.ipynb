{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "projekt5.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XyeFeWjJqeT",
    "outputId": "0df72eaa-730f-4830-a0a0-137f49415ea3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# !cp drive/MyDrive/ssne/train.pkl train.pkl\n",
    "# !cp drive/MyDrive/ssne/test_no_target.pkl test_no_target.pkl"
   ],
   "metadata": {
    "id": "y1uVauLjKEns"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn.functional import one_hot"
   ],
   "metadata": {
    "id": "PPq5zlqAKKeu"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open('train.pkl', 'rb') as file:\n",
    "  data = pickle.load(file)"
   ],
   "metadata": {
    "id": "oi6i_4tYMFAf"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQwxafxKDtfx",
    "outputId": "b5486d02-f82b-4a09-cc04-88c160c22247"
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class ClassicalMusicDataset(Dataset):\n",
    "  def __init__(self, features, targets):\n",
    "    self.features = [torch.Tensor(f).float() for f in features]\n",
    "    self.targets = targets\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.features[idx], self.targets[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.features)\n"
   ],
   "metadata": {
    "id": "pBe78yhVbSlD"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    " classes = {0: 'bach', 1: 'beethoven', 2: 'debussy', 3: 'scarlatti', 4: 'victoria'}"
   ],
   "metadata": {
    "id": "QtDZn6zI7mK6"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "features, labels = [], []\n",
    "for feature, label in data:\n",
    "  features.append(feature)\n",
    "  labels.append(label)\n",
    "\n",
    "features, labels = np.array(features, dtype=object), np.array(labels)"
   ],
   "metadata": {
    "id": "0NMCK5u-cYlB"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TEST_TRAIN_RATIO = 0.2\n",
    "\n",
    "train_indices = np.random.rand(len(features)) > TEST_TRAIN_RATIO\n",
    "test_indices = ~train_indices\n",
    "\n",
    "train_set = ClassicalMusicDataset(features[train_indices], labels[train_indices])\n",
    "test_set = ClassicalMusicDataset(features[test_indices], labels[test_indices])"
   ],
   "metadata": {
    "id": "rr4a6a1fdAJ-"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def pad_collate(batch):\n",
    "  (xx, yy) = zip(*batch)\n",
    "  x_lens = [len(x) for x in xx]\n",
    "\n",
    "  xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "\n",
    "  return xx_pad, yy, x_lens"
   ],
   "metadata": {
    "id": "gK5J-vE3dFCy"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_loader = DataLoader(dataset=train_set, batch_size=32, shuffle=True, collate_fn=pad_collate, drop_last=True)\n",
    "test_data_loader = DataLoader(dataset=train_set, batch_size=len(test_set), collate_fn=pad_collate)"
   ],
   "metadata": {
    "id": "7rsv8vDBdrcv"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RNNRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        self.rnn = nn.GRU(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, out_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, x, x_len, hidden):\n",
    "        packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
    "        all_outputs, hidden = self.rnn(packed, hidden)\n",
    "        all_outputs, _ = pad_packed_sequence(all_outputs, batch_first=True, padding_value=0)\n",
    "        out = all_outputs[:,-1,:] # We are interested only on the last output\n",
    "        x = self.fc(out.float())\n",
    "        x = self.softmax(x)\n",
    "        return x, hidden"
   ],
   "metadata": {
    "id": "4QkNpZI5dxJZ"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = RNNRegressor(1, 64, 2, len(classes)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "  for x,targets,x_len in data_loader:\n",
    "    x = x.unsqueeze(2).to(device)\n",
    "    targets = torch.LongTensor(targets).to(device)\n",
    "    targets = one_hot(targets, len(classes))\n",
    "    hidden = model.init_hidden(64)\n",
    "    hidden = hidden.to(device)\n",
    "    preds, _ = model(x,x_len, hidden)\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fun(preds, targets.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixqc5s5OpqrH",
    "outputId": "bbdf494a-1d05-4853-b7ac-92b19a1f4473"
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kubar\\AppData\\Local\\Temp/ipykernel_25564/2162881845.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.16\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "for x, targets, x_len in test_data_loader:\n",
    "    x = x.unsqueeze(2).to(device)\n",
    "    targets = torch.LongTensor(targets).to(device)\n",
    "    targets = one_hot(targets, len(classes))\n",
    "    hidden = model.init_hidden(64)\n",
    "    hidden = hidden.to(device)\n",
    "    preds, _ = model(x,x_len, hidden)"
   ],
   "metadata": {
    "id": "mNaTQe1mI-Vu",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "outputId": "b9cb467d-12fe-4c27-9af0-f66c33e7ff95"
   },
   "execution_count": 14,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25564/2552402607.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mhidden\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit_hidden\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mhidden\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mpreds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mx_len\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\kubar\\documents\\studia\\ssne\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25564/2162881845.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, x_len, hidden)\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_len\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[0mpacked\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpack_padded_sequence\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_len\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_first\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menforce_sorted\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[0mall_outputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrnn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpacked\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m         \u001B[0mall_outputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpad_packed_sequence\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_outputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_first\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding_value\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mall_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;31m# We are interested only on the last output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kubar\\documents\\studia\\ssne\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\kubar\\documents\\studia\\ssne\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    850\u001B[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001B[0;32m    851\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 852\u001B[1;33m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001B[0m\u001B[0;32m    853\u001B[0m                              self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001B[0;32m    854\u001B[0m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "KX4tUsR-qYf6"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}