{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_best.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IhYukKmCUmc",
        "outputId": "b6e1a6fc-548a-4c70-a46c-32098d1831ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/ssne/train.pkl train.pkl\n",
        "!cp drive/MyDrive/ssne/test_no_target.pkl test_no_target.pkl"
      ],
      "metadata": {
        "id": "2LkC-0L7CVM_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iJH167C75too"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sklearn\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3dOBDAIiHk0",
        "outputId": "3fc50891-58b7-461b-8ec8-edbbc1d65d8c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 742842589\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "KUDzlTUYqo6A"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw = pd.read_pickle(\"./train.pkl\")\n",
        "random.shuffle(train_raw)"
      ],
      "metadata": {
        "id": "KHzXs6WANS5R"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: {0: 1630, 2: 154, 3: 441, 4: 236, 1: 478}\n",
            "Min class: 154\n"
          ]
        }
      ],
      "source": [
        "def count_classes(train_set):\n",
        "  classes_count = {}\n",
        "  for x in train_set:\n",
        "    classes_count[x[1]] = classes_count.get(x[1], 0) + 1\n",
        "  return classes_count\n",
        "\n",
        "print(f\"Classes: {count_classes(train_raw)}\")\n",
        "min_class_count = min(count_classes(train_raw).values())\n",
        "print(f\"Min class: {min_class_count}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9iypHPuACfr",
        "outputId": "d958b05f-fa19-4343-ca3f-b35e7bdb7bac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Balancing\n",
        "CLASS_COUNT_LIMIT = 5*min_class_count\n",
        "\n",
        "train_balanced = []\n",
        "classes_counter = {}\n",
        "for x in train_raw:\n",
        "  classes_counter[x[1]] = classes_counter.get(x[1], 0) + 1\n",
        "  if classes_counter[x[1]] <= CLASS_COUNT_LIMIT:\n",
        "    train_balanced.append(x)\n",
        "\n",
        "train_raw = train_balanced\n",
        "print(f\"Classes: {count_classes(train_raw)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSUov6Wwf6ol",
        "outputId": "6090b378-0db5-4048-ede6-9c28bc1cf549"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: {0: 770, 2: 154, 3: 441, 4: 236, 1: 478}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = []\n",
        "for x in train_raw:\n",
        "  sizes.append(x[0].shape[0])\n",
        "print(f\"Sequence size [min/avr/max]: {min(sizes)}/{sum(sizes)/len(sizes)}/{max(sizes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BGmH0F5ixSC",
        "outputId": "42536092-fe75-4292-ee91-8fe99c15f858"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence size [min/avr/max]: 4/473.93265993265993/6308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -1.,  -1.,   0.,   0.,   0.,  12.,  12.,  88.,  92.,  92.,  28., 159.,\n",
              "         12.,   0.,   0., 144., 144., 144.,  50.,  50.,  50., 116., 116., 116.,\n",
              "        122., 122., 122., 127.,  88.,  88., 125.,  78., 119., 159., 125.,  47.,\n",
              "         78.,  64., 159.,  92.,  88.,  47.,  12.,   0.,  12.,  12.,  15.,  45.,\n",
              "        124., 112.,  12.,  13., 141.,  12.,  88.,  13.,  92.,  92.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Croping\n",
        "MAX_SEQUENCE_LEN = 40000\n",
        "\n",
        "music_data = []\n",
        "label_data = []\n",
        "for x in train_raw:\n",
        "  music_tensor = torch.tensor(x[0], dtype=torch.float)\n",
        "  music_tensor = music_tensor[:MAX_SEQUENCE_LEN]\n",
        "  music_data.append(music_tensor)\n",
        "  label_data.append(x[1])\n",
        "music_data[0]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSrNWssvACfr",
        "outputId": "7277aa66-159f-49cb-a94e-c3be20296fb0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size after paddding: 6308\n"
          ]
        }
      ],
      "source": [
        "music_data_padded = pad_sequence(music_data, batch_first=True, padding_value=0)\n",
        "assert len(music_data_padded) == len(label_data)\n",
        "print(f\"Size after paddding: {music_data_padded[0].shape[0]}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yySQ4RdlACfs",
        "outputId": "282026c3-2541-43ef-c01e-fe1b9d084f2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_TEST_RATIO = 0.9\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_indices = int(TRAIN_TEST_RATIO*len(music_data_padded))\n",
        "\n",
        "train_set = torch.utils.data.TensorDataset(music_data_padded[:train_indices], torch.tensor(label_data[:train_indices]))\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data, test_targets = music_data_padded[train_indices:], label_data[train_indices:]"
      ],
      "metadata": {
        "id": "WfRYdHZAEoMP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [],
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
        "    self.fc = nn.Linear(hidden_size*len(music_data_padded[0]), out_size)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "    state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "    return hidden, state\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    x = torch.transpose(x, 0, 1)\n",
        "    all_outputs, hidden = self.lstm(x, hidden)\n",
        "    all_outputs = torch.transpose(all_outputs,0,1)\n",
        "    out = torch.flatten(all_outputs, 1)\n",
        "    x = self.fc(out)\n",
        "  \n",
        "    return x, hidden"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ixq24WW8ACft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [],
      "source": [
        "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(label_data),y=label_data)\n",
        "class_weights = torch.tensor(class_weights).float()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3GP-7fHNACfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [],
      "source": [
        "def count_accuracy():\n",
        "  with torch.no_grad():\n",
        "    hidden, state = model.init_hidden(len(test_data))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "    preds, _ = model(test_data.to(device).unsqueeze(2),(hidden, state))\n",
        "    p = torch.argmax(preds,1).cpu()\n",
        "    counter = 0\n",
        "    for i in range(len(test_targets)):\n",
        "      if p[i] == test_targets[i]:\n",
        "        counter += 1\n",
        "    return counter/len(test_targets)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aNrDdbQvACfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMRegressor(1, 60, 3, 5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_fun = nn.CrossEntropyLoss(weight = class_weights.to(device))"
      ],
      "metadata": {
        "id": "pzVJESXPE1zy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 1.05, acc: 0.582, max_acc: 0.582\n",
            "Epoch: 1, loss: 0.854, acc: 0.635, max_acc: 0.635\n",
            "Epoch: 2, loss: 0.727, acc: 0.668, max_acc: 0.668\n",
            "Epoch: 3, loss: 0.68, acc: 0.702, max_acc: 0.702\n",
            "Epoch: 4, loss: 0.593, acc: 0.678, max_acc: 0.702\n",
            "Epoch: 5, loss: 0.567, acc: 0.678, max_acc: 0.702\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "max_acc = 0\n",
        "for epoch in range(6):\n",
        "  for x, targets in train_loader:\n",
        "    x = x.to(device).unsqueeze(2)\n",
        "    targets = targets.to(device)\n",
        "    hidden, state = model.init_hidden(x.size(0))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "    preds, _ = model(x, (hidden,state))\n",
        "    preds = preds.squeeze(1)\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fun(preds, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  acc = count_accuracy()\n",
        "  max_acc = max(max_acc, acc)\n",
        "  if max_acc - acc > 0.05:\n",
        "    break\n",
        "  print(f\"Epoch: {epoch}, loss: {loss.item():.3}, acc: {acc:.3}, max_acc: {max_acc:.3}\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YTmM87qGACfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e752f8-ef5a-4a6d-cc50-5ddfa8019719"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "source": [
        "def save_results(tensor):\n",
        "  predictions = tensor.cpu().detach().numpy()\n",
        "  pd.DataFrame(predictions).to_csv(\"result.csv\",header=False, index=False)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RCx8YjssACfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_raw = pd.read_pickle(\"./test_no_target.pkl\")"
      ],
      "metadata": {
        "id": "Vl5sysX2EIxD"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}