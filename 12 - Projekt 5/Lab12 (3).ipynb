{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab12.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQWsxQ4NYOkd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "import gzip\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "import sklearn.utils.class_weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6siEOfhYa_mV",
        "outputId": "9819e482-edd9-4423-b9d1-ee7d2618d8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bwPolTdMbBeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0c8f0f-7efb-4d38-d216-e30c0dc168f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = shuffle(pd.read_pickle('/content/drive/MyDrive/train.pkl'))"
      ],
      "metadata": {
        "id": "TEMAJY5zSsIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "for element in dt:\n",
        "  x.append(torch.tensor(element[0]).float())\n",
        "  y.append(element[1])\n"
      ],
      "metadata": {
        "id": "i3e23J7DrGiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_padded = pad_sequence(x, batch_first=True)\n",
        "len(x_padded[0])"
      ],
      "metadata": {
        "id": "T23AmYK8uOEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b2e02e-b991-4d25-ff4a-11dbd8c0e5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6308"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = int(0.7*len(y))\n",
        "\n",
        "train_set = data.TensorDataset(torch.tensor(x_padded[:train_indices]), torch.tensor(y[:train_indices]))\n",
        "train_loader = data.DataLoader(train_set, batch_size=32)\n",
        "test_data, test_targets = x_padded[train_indices:], y[train_indices:]\n"
      ],
      "metadata": {
        "id": "m89H8K-5eXmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92f087c-d7e2-456b-b2dc-705b0f9d3ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oLMBJGg5sgKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional = bidirectional, dropout=0.4)\n",
        "        if bidirectional:\n",
        "          self.bidirectional = 2\n",
        "        else:\n",
        "          self.bidirectional = 1\n",
        "        self.fc = nn.Linear(hidden_size*len(x_padded[0])*self.bidirectional, out_size)\n",
        "\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional, batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional, batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x = torch.transpose(x,0,1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        all_outputs = torch.transpose(all_outputs,0,1)\n",
        "        out = torch.flatten(all_outputs, 1)\n",
        "        x = self.fc(out)\n",
        "        return x, hidden\n",
        "\n",
        "\n",
        "model = LSTMRegressor(1,20,3,5,False).to(device)"
      ],
      "metadata": {
        "id": "wXMEfvZrY8Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(y),y=y)\n",
        "class_weights = torch.tensor(class_weights).float()"
      ],
      "metadata": {
        "id": "GTRyJgMJcoF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_accuracy():\n",
        "  with torch.no_grad():\n",
        "    hidden, state = model.init_hidden(len(test_data))\n",
        "    hidden, state = hidden.to(device), state.to(device) \n",
        "    preds, _ = model(test_data.to(device).unsqueeze(2),(hidden, state))\n",
        "  p = torch.argmax(preds,1).cpu()\n",
        "  counter = 0\n",
        "  for i in range(len(test_targets)):\n",
        "    if p[i] == test_targets[i]:\n",
        "      counter += 1\n",
        "  return counter/len(test_targets)\n"
      ],
      "metadata": {
        "id": "NviXv2oqxvMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jixM5b_0Qpfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "loss_fun = nn.CrossEntropyLoss(weight = class_weights.to(device))\n",
        "last_acc = 0\n",
        "# Training loop\n",
        "for epoch in range(30):\n",
        "    for x, targets in train_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device) \n",
        "        preds, _ = model(x, (hidden,state))\n",
        "        preds = preds.squeeze(1)\n",
        "        optimizer.zero_grad() \n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    acc = count_accuracy()\n",
        "    print(f\"Epoch: {epoch}, loss: {loss.item():.3} acc: {acc:.3}\")\n",
        "    if acc - last_acc < -0.1:\n",
        "      break\n",
        "    last_acc = acc"
      ],
      "metadata": {
        "id": "1VSGw_PxO_U4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "76733e07-5718-4ca4-bf3a-2b016f923a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-02f523717456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = LSTMRegressor(1,10,2,5,True).to(device)"
      ],
      "metadata": {
        "id": "H7jgYWKBsYcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aTwkAyHUqftm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hidden, state = model.init_hidden(len(test_data))\n",
        "    hidden, state = hidden.to(device), state.to(device) \n",
        "    preds, _ = model(test_data.to(device).unsqueeze(2),(hidden, state))\n",
        "# print(f\"Accuracy: {(torch.argmax(preds,1).cpu() == test_targets).sum().item()/len(test_targets)}\")"
      ],
      "metadata": {
        "id": "-PH8tR8Skz0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = torch.argmax(preds,1).cpu()\n",
        "counter = 0\n",
        "for i in range(len(test_targets)):\n",
        "  if p[i] == test_targets[i]:\n",
        "    counter += 1\n",
        "print(counter/len(test_targets))\n"
      ],
      "metadata": {
        "id": "5-FOfHtCqMCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63a8854-8316-4f86-dc32-98c125ce2920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4886621315192744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(tensor):\n",
        "  predictions = tensor.cpu().detach().numpy()\n",
        "  pd.DataFrame(predictions).to_csv(\"MatakGromadzka.csv\",header=False, index=False)"
      ],
      "metadata": {
        "id": "GS-GaWODVRmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dW-Rj1ZYVTen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MtC1v96duaYn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}